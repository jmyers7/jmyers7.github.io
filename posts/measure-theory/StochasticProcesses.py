"""
Stochastic Process Classes for Discrete-Time Processes

This module will provide base classes and implementations for common discrete-time
stochastic processes, including Markov chains and betting strategies.

Classes
-------
StochasticProcess
    Abstract base class for all stochastic processes
TwoStateMarkovChain
    Two-state Markov chain with configurable transition probabilities
ThreeWinStreakSelection
    Betting strategy based on three consecutive wins

Examples
--------
>>> # Create a Markov chain
>>> mc = TwoStateMarkovChain(alpha=0.8, beta=0.3, chain_length=3)
>>> mc.setup_sample_space()
>>> print(mc.omega)

>>> # Simulate trajectories
>>> mc_long = TwoStateMarkovChain(chain_length=1000)
>>> mc_long.plot_simulations(num_chains=10)

>>> # Compute conditional expectations
>>> E_S2_X1 = mc.conditional_expectation("S2", ["X1"])
"""

import numpy as np
import matplotlib.pyplot as plt
from itertools import product
import pandas as pd
import math


class StochasticProcess:
    """
    Abstract base class for discrete-time stochastic processes.

    This class provides the interface for stochastic processes with a finite
    time horizon. Subclasses must implement methods for sample space generation,
    probability computation, and simulation.

    Parameters
    ----------
    chain_length : int, default=3
        Number of time steps in the process

    Attributes
    ----------
    chain_length : int
        Number of time steps
    omega : pandas.DataFrame or None
        Sample space with all possible realizations and their probabilities.
        Initially None; populated by calling setup_sample_space()

    Notes
    -----
    The sample space is not generated automatically to allow efficient simulation
    of long chains without constructing an exponentially large sample space.
    """

    def __init__(self, chain_length=3):
        self.chain_length = chain_length
        self.omega = None

    def setup_sample_space(self):
        """
        Generate the complete sample space Omega.

        This method must be implemented by subclasses. It should populate
        self.omega with a DataFrame containing all possible realizations
        and their probabilities.

        Returns
        -------
        self
            Returns self for method chaining

        Raises
        ------
        NotImplementedError
            If not implemented by subclass

        Warnings
        --------
        For processes with large chain_length, the sample space may be
        exponentially large and computationally infeasible to construct.
        Use simulate() for practical applications with long chains.
        """
        raise NotImplementedError("Subclasses must implement setup_sample_space")

    def joint_prob(self, x):
        """
        Compute the joint probability P(X_1, ..., X_n) for a sequence.

        Parameters
        ----------
        x : array-like
            A realization of the process

        Returns
        -------
        float
            Joint probability of the sequence

        Raises
        ------
        NotImplementedError
            If not implemented by subclass
        """
        raise NotImplementedError("Subclasses must implement joint_prob")

    def simulate(self, num_chains=1):
        """
        Generate sample paths from the process.

        Parameters
        ----------
        num_chains : int, default=1
            Number of independent realizations to generate

        Returns
        -------
        array-like
            Simulated trajectories. Format depends on subclass implementation.

        Raises
        ------
        NotImplementedError
            If not implemented by subclass
        """
        raise NotImplementedError("Subclasses must implement simulate")

    def conditional_expectation(self, Y, sigma_algebra):
        """
        Compute conditional expectation E(Y | sigma-algebra).

        This method computes the conditional expectation of a random variable Y
        with respect to a sigma-algebra generated by the specified columns.

        Parameters
        ----------
        Y : str or callable
            Either a column name in self.omega, or a function that takes
            self.omega and returns a Series of values
        sigma_algebra : list of str
            Column names that generate the conditioning sigma-algebra

        Returns
        -------
        pandas.Series
            Conditional expectation values, indexed by the atoms of the
            sigma-algebra

        Raises
        ------
        ValueError
            If sample space has not been initialized via setup_sample_space()

        Examples
        --------
        >>> mc = TwoStateMarkovChain(chain_length=3)
        >>> mc.setup_sample_space()
        >>> E_S2_X1 = mc.conditional_expectation("S2", ["X1"])
        >>> print(E_S2_X1)
        """
        if self.omega is None:
            raise ValueError(
                "Sample space not initialized. Call setup_sample_space() first."
            )

        # Extract Y values
        if isinstance(Y, str):
            Y_values = self.omega[Y]
        else:
            Y_values = Y(self.omega)

        # Compute conditional probabilities within each atom
        p_cond_col = f"p_{'_'.join(sigma_algebra)}"
        self.omega[p_cond_col] = self.omega.groupby(sigma_algebra)["p"].transform(
            lambda x: x / x.sum()
        )

        # Compute conditional expectation for each atom
        result = self.omega.groupby(sigma_algebra).apply(
            lambda g: (Y_values.loc[g.index] * g[p_cond_col]).sum(),
            include_groups=False,
        )

        # Clean up temporary column
        self.omega.drop(columns=[p_cond_col], inplace=True)

        return result


class TwoStateMarkovChain(StochasticProcess):
    """
    Two-state Markov chain with configurable transition probabilities.

    Models a discrete-time Markov chain on state space {0, 1} with transition
    probabilities:
        P(X_{n+1} = 1 | X_n = 1) = alpha
        P(X_{n+1} = 1 | X_n = 0) = beta

    Parameters
    ----------
    alpha : float, default=0.8
        Probability of staying in state 1 given current state is 1.
        Must be in [0, 1].
    beta : float, default=0.3
        Probability of transitioning to state 1 given current state is 0.
        Must be in [0, 1].
    theta : float, default=0.5
        Initial probability P(X_1 = 1). Must be in [0, 1].
    chain_length : int, default=3
        Number of time steps in the chain

    Attributes
    ----------
    alpha : float
        Transition probability P(1|1)
    beta : float
        Transition probability P(1|0)
    theta : float
        Initial probability P(X_1 = 1)
    omega : pandas.DataFrame or None
        Sample space containing all possible sequences and their probabilities.
        Columns include X1, X2, ..., Xn (states), S1, S2, ..., Sn (cumulative
        sums), and p (probabilities).

    Examples
    --------
    >>> # Short chain with sample space
    >>> mc = TwoStateMarkovChain(alpha=0.8, beta=0.3, chain_length=3)
    >>> mc.setup_sample_space()
    >>> print(mc.omega)
    >>> E_S2_X1 = mc.conditional_expectation("S2", ["X1"])

    >>> # Long chain - simulate without sample space
    >>> mc_long = TwoStateMarkovChain(chain_length=1000)
    >>> chains = mc_long.simulate(num_chains=100)
    >>> mc_long.plot_simulations(num_chains=10)
    """

    def __init__(self, alpha=0.8, beta=0.3, theta=0.5, chain_length=3):
        self.alpha = alpha
        self.beta = beta
        self.theta = theta
        super().__init__(chain_length)

    def setup_sample_space(self):
        """
        Generate complete sample space of all possible state sequences.

        Creates a DataFrame with all 2^n possible sequences of length n,
        along with cumulative sums and joint probabilities.

        Returns
        -------
        self
            Returns self for method chaining

        Warnings
        --------
        Computational complexity is O(2^n) in chain_length. For long chain lengths,
        consider using simulate() instead.
        """
        # Generate all binary sequences
        sequences = list(product([0, 1], repeat=self.chain_length))
        column_names = [f"X{i+1}" for i in range(self.chain_length)]
        self.omega = pd.DataFrame(sequences, columns=column_names)

        # Add cumulative sums S_n = X_1 + ... + X_n
        S = self.omega.apply(np.cumsum, axis=1)
        S.columns = [f"S{i+1}" for i in range(self.chain_length)]
        self.omega = pd.concat([self.omega, S], axis=1)

        # Compute joint probabilities using chain rule
        self.omega["p"] = self.omega[column_names].apply(
            lambda row: self.joint_prob(row.tolist()), axis=1
        )

        return self

    def _trans_prob(self, y, x):
        """
        Compute one-step transition probability P(Y | X).

        Parameters
        ----------
        y : int
            Next state (0 or 1)
        x : int
            Current state (0 or 1)

        Returns
        -------
        float
            Transition probability P(Y | X)
        """
        match (y, x):
            case (0, 0):
                return 1 - self.beta
            case (0, 1):
                return 1 - self.alpha
            case (1, 0):
                return self.beta
            case (1, 1):
                return self.alpha

    def _init_prob(self, x):
        """
        Compute initial probability P(X_1 = x).

        Parameters
        ----------
        x : int
            Initial state (0 or 1)

        Returns
        -------
        float
            Initial probability
        """
        return self.theta**x * (1 - self.theta) ** (1 - x)

    def joint_prob(self, x):
        """
        Compute joint probability P(X_1, ..., X_n) using chain rule.

        Applies the Markov property:
            P(X_1, ..., X_n) = P(X_1) * P(X_2|X_1) * ... * P(X_n|X_{n-1})

        Parameters
        ----------
        x : list or array-like
            State sequence of length n

        Returns
        -------
        float
            Joint probability of the sequence
        """
        return self._init_prob(x[0]) * math.prod(
            [self._trans_prob(x[i], x[i - 1]) for i in range(1, len(x))]
        )

    def simulate(self, num_chains=1):
        """
        Generate sample paths from the Markov chain.

        Parameters
        ----------
        num_chains : int, default=1
            Number of independent chains to simulate

        Returns
        -------
        numpy.ndarray
            Array of shape (num_chains, chain_length) containing simulated
            state sequences

        Examples
        --------
        >>> mc = TwoStateMarkovChain(chain_length=100)
        >>> chains = mc.simulate(num_chains=1000)
        >>> print(chains.shape)  # (1000, 100)
        >>> print(chains.mean())  # Should be close to stationary probability
        """
        chains = np.zeros((num_chains, self.chain_length), dtype=int)

        # Sample initial states from Bernoulli(theta)
        chains[:, 0] = np.random.binomial(1, self.theta, size=num_chains)

        # Generate subsequent states using transition probabilities
        for i in range(1, self.chain_length):
            # Transition probability depends on previous state
            probs = np.where(chains[:, i - 1] == 1, self.alpha, self.beta)
            chains[:, i] = np.random.binomial(1, probs)

        return chains

    def plot_simulations(
        self, num_chains=10, cumulative=True, colors=None, alpha=0.7, figsize=None
    ):
        """
        Visualize simulated trajectories.

        Parameters
        ----------
        num_chains : int, default=10
            Number of trajectories to simulate and plot
        cumulative : bool, default=True
            If True, plot cumulative sums S_n = X_1 + ... + X_n.
            If False, plot raw states X_n.
        colors : list of str, optional
            Custom colors for each trajectory. If None, uses default color cycle.
        alpha : float, default=1
            Transparency level for trajectory lines. Must be in [0, 1].
        figsize : tuple of float, optional
            Figure size as (width, height) in inches. If None, uses default (10, 6).

        Examples
        --------
        >>> mc = TwoStateMarkovChain(chain_length=100)
        >>> mc.plot_simulations(num_chains=5)
        >>> mc.plot_simulations(num_chains=3, colors=['red', 'blue', 'green'])
        >>>
        >>> # Custom transparency and size
        >>> mc.plot_simulations(num_chains=10, alpha=1, figsize=(12, 8))
        """
        chains = self.simulate(num_chains)

        if cumulative:
            data = np.cumsum(chains, axis=1)
            ylabel = "cumulative sum"
        else:
            data = chains
            ylabel = "state"

        if figsize is not None:
            _, ax = plt.subplots(figsize=figsize)
        else:
            _, ax = plt.subplots(figsize=(10, 6))

        for i, series in enumerate(data):
            if colors is None:
                ax.plot(range(self.chain_length), series, alpha=alpha)
            else:
                ax.plot(range(self.chain_length), series, color=colors[i], alpha=alpha)

        ax.set_xlabel("time")
        ax.set_ylabel(ylabel)
        ax.set_title(f"2-state markov chain (α={self.alpha}, β={self.beta})")
        plt.tight_layout()
        plt.show()


class ThreeWinStreakSelectionStrategy(StochasticProcess):
    """
    Betting strategy where bets are placed only after three consecutive wins.

    Models a gambling strategy where a bettor observes a sequence of wins and
    losses but only places a bet after observing three consecutive wins. When
    no bet is placed, the capital remains unchanged (bet outcome = 0). Capital
    evolves based on the outcomes of these selective bets.

    Parameters
    ----------
    theta : float
        Probability of winning a single trial. Must be in [0, 1].
    chain_length : int
        Number of trials to observe (time horizon)
    a : float, default=0
        Initial capital. Must be non-negative.

    Attributes
    ----------
    theta : float
        Win probability for each trial
    a : float
        Initial capital
    omega : pandas.DataFrame or None
        Sample space containing all win/loss sequences and probabilities.
        Columns include:
        - X1, X2, ..., Xn: Trial outcomes (±1 for win/loss)
        - B1, B2, ..., Bn: Bet outcomes (0 for no bet, ±1 for bet result)
        - S0, S1, ..., Sn: Capital at each time (S0 = initial capital)
        - p: Joint probabilities

    Raises
    ------
    ValueError
        If theta is not in [0, 1] or a is negative

    Notes
    -----
    The capital process S_n represents wealth after observing n trials. When
    no bet is placed (first three trials or after non-winning sequences),
    B_n = 0 and capital remains unchanged: S_n = S_{n-1}.

    The process is path-dependent: identical final win/loss counts can lead
    to different capital depending on the timing of three-win streaks.

    Examples
    --------
    >>> # Simulate long trajectory
    >>> process = ThreeWinStreakSelectionStrategy(theta=0.6, chain_length=100, a=10)
    >>> process.plot_simulations(num_chains=10)

    >>> # Analyze small sample space
    >>> small = ThreeWinStreakSelectionStrategy(theta=0.6, chain_length=5, a=10)
    >>> small.setup_sample_space()
    >>> print(small.omega)
    >>> E_final = (small.omega['S5'] * small.omega['p']).sum()
    """

    def __init__(self, theta, chain_length, a=0):
        # Validate parameters
        if not 0 <= theta <= 1:
            raise ValueError("theta must be a probability between 0 and 1")
        if a < 0:
            raise ValueError("a must be nonnegative")

        super().__init__(chain_length)
        self.theta = theta
        self.a = a

    def setup_sample_space(self):
        """
        Generate complete sample space of all win/loss sequences.

        Creates a DataFrame with all 2^n possible trial sequences, bet outcomes,
        capital trajectories, and probabilities.

        Returns
        -------
        self
            Returns self for method chaining

        Warnings
        --------
        Complexity is O(2^n) in chain_length. Infeasible for long chain lengths.
        Use simulate() instead for longer chains.

        Notes
        -----
        The resulting DataFrame contains:
        - X1, ..., Xn: Trial outcomes (±1)
        - B1, ..., Bn: Bet outcomes (0 if no bet, ±1 if bet placed)
        - S0, ..., Sn: Capital at each time step (S0 is initial capital)
        - p: Joint probability of each sequence
        """
        # Generate all possible win (+1) / loss (-1) sequences
        sequences = list(product([-1, 1], repeat=self.chain_length))
        X_names = [f"X{i+1}" for i in range(self.chain_length)]
        self.omega = pd.DataFrame(sequences, columns=X_names)

        # Generate bet outcomes (0 when no bet placed, ±1 when bet placed)
        bet_outcomes = self.omega.apply(self._generate_bet_outcomes, axis=1)
        bet_df = pd.DataFrame(bet_outcomes.tolist())
        bet_df.columns = [f"B{i+1}" for i in range(self.chain_length)]

        # Generate capital trajectories (includes S0 = initial capital)
        capitals = bet_df.apply(self._compute_capital, axis=1)
        capitals_df = pd.DataFrame(capitals.tolist())
        capitals_df.columns = [f"S{i}" for i in range(self.chain_length + 1)]

        # Concatenate all columns
        self.omega = pd.concat([self.omega, bet_df, capitals_df], axis=1)

        # Compute probabilities based on number of wins
        num_wins = (self.omega[X_names] == 1).sum(axis=1)
        self.omega["p"] = self.theta**num_wins * (1 - self.theta) ** (
            self.chain_length - num_wins
        )

        return self

    def joint_prob(self, X):
        """
        Compute probability of a win/loss sequence.

        Assumes independent trials with success probability theta.

        Parameters
        ----------
        X : array-like
            Sequence of wins (1) and losses (-1)

        Returns
        -------
        float
            Probability of observing this sequence
        """
        num_wins = sum(1 for win in X if win == 1)
        num_losses = len(X) - num_wins
        return self.theta**num_wins * (1 - self.theta) ** num_losses

    def _generate_wins_losses(self):
        """
        Generate one random sequence of wins and losses.

        Returns
        -------
        numpy.ndarray
            Array of length chain_length with values in {-1, 1} where
            1 represents a win and -1 represents a loss
        """
        X = np.random.binomial(1, self.theta, size=self.chain_length)
        X = np.where(X == 1, 1, -1)
        return X

    def _generate_bet_outcomes(self, X):
        """
        Generate bet outcomes from trial sequence.

        A bet is placed at time t if trials X[t-3], X[t-2], X[t-1] are all
        wins. The bet outcome B[t] equals X[t] (the next trial's outcome).
        When no bet is placed, B[t] = 0.

        Parameters
        ----------
        X : array-like
            Complete sequence of trial outcomes (±1)

        Returns
        -------
        numpy.ndarray
            Bet outcomes at each time step. Length equals len(X).
            Values are 0 (no bet), 1 (bet placed and won), or -1 (bet placed and lost).

        Notes
        -----
        First three positions are always 0 since at least three previous trials
        are needed to trigger a bet.
        """
        X = np.array(X)
        B = [0, 0, 0]  # No bets can be placed in first three trials

        for t in range(3, len(X)):
            # Check if previous three trials were all wins
            if np.all(X[t - 3 : t] == 1):
                B.append(X[t])  # Place bet with outcome = current trial
            else:
                B.append(0)  # No bet placed

        return np.array(B)

    def _compute_capital(self, B):
        """
        Compute capital trajectory from bet outcomes.

        Capital starts at initial value a and changes by +1 or -1 when bets
        are placed. When B[t] = 0 (no bet), capital remains unchanged.

        Parameters
        ----------
        B : array-like
            Bet outcomes at each time step (0, +1, or -1)

        Returns
        -------
        numpy.ndarray
            Capital values S0, S1, ..., Sn where S0 = a (initial capital)
            and S_t = S_{t-1} + B_t for t >= 1.
            Length is len(B) + 1.
        """
        # S_t = a + sum of all bet outcomes up to time t
        S = np.concatenate([[self.a], self.a + np.cumsum(B)])
        return S

    def simulate(self, num_chains=1):
        """
        Generate sample capital trajectories.

        Parameters
        ----------
        num_chains : int, default=1
            Number of independent trajectories to simulate

        Returns
        -------
        list of numpy.ndarray
            Each array contains capital values S0, S1, ..., Sn for one trajectory.
            All arrays have length chain_length + 1.

        Examples
        --------
        >>> process = ThreeWinStreakSelectionStrategy(theta=0.6, chain_length=100, a=10)
        >>> trajectories = process.simulate(num_chains=1000)
        >>> final_capitals = [S[-1] for S in trajectories]
        >>> print(f"Mean final capital: ${np.mean(final_capitals):.2f}")
        >>> print(f"Std final capital: ${np.std(final_capitals):.2f}")
        """
        trajectories = []

        for _ in range(num_chains):
            X = self._generate_wins_losses()  # Trial outcomes (±1)
            B = self._generate_bet_outcomes(X)  # Bet outcomes (0 or ±1)
            S = self._compute_capital(B)  # Capital trajectory
            trajectories.append(S)

        return trajectories

    def plot_simulations(self, num_chains=10, colors=None, alpha=1, figsize=None):
        """
        Visualize capital trajectories over time.

        Plots show how capital evolves over the observation period. Horizontal
        line indicates initial capital.

        Parameters
        ----------
        num_chains : int, default=10
            Number of trajectories to simulate and plot
        colors : list of str, optional
            Custom colors for each trajectory. If None, uses default color cycle.
            Should have length >= num_chains.
        alpha : float, default=1
            Transparency level for trajectory lines. Must be in [0, 1].
        figsize : tuple of float, optional
            Figure size as (width, height) in inches. If None, uses matplotlib default.

        Examples
        --------
        >>> process = ThreeWinStreakSelectionStrategy(theta=0.6, chain_length=100, a=10)
        >>> process.plot_simulations(num_chains=10)
        >>>
        >>> # Custom colors and transparency
        >>> colors = ['red', 'blue', 'green']
        >>> process.plot_simulations(num_chains=3, colors=colors, alpha=0.5)
        >>>
        >>> # Custom figure size
        >>> process.plot_simulations(num_chains=10, figsize=(12, 8))
        """
        trajectories = self.simulate(num_chains)

        if figsize is not None:
            _, ax = plt.subplots(figsize=figsize)
        else:
            _, ax = plt.subplots()

        for i, S in enumerate(trajectories):
            time_steps = range(len(S))

            if colors is None:
                ax.plot(time_steps, S, alpha=alpha)
            else:
                ax.plot(time_steps, S, color=colors[i], alpha=alpha)

        ax.set_xlabel("time")
        ax.set_ylabel("capital")
        ax.set_title(
            f"three-win streak selection strategy (θ={self.theta}, initial capital={self.a})"
        )
        plt.tight_layout()
        plt.show()
