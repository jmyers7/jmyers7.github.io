<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.24">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2026-02-03">

<title>PyTorch and derivatives: A mathematical perspective – john myers, ph.d.</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../img/fav.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-367851019e9ccd243b94edaf001a4bfd.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-4853ac07ca6a7896c17d72d590de6080.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-VWK3RHBGT2"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-VWK3RHBGT2', { 'anonymize_ip': true});
</script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100..900;1,100..900&amp;family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&amp;family=Nunito:ital,wght@0,200..1000;1,200..1000&amp;display=swap" rel="stylesheet">
<meta name="quarto:status" content="draft">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="PyTorch and derivatives: A mathematical perspective">
<meta property="og:description" content="">
<meta property="og:site_name" content="john myers, ph.d.">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><div id="quarto-draft-alert" class="alert alert-warning"><i class="bi bi-pencil-square"></i>Draft</div>
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../writings.html"> 
<span class="menu-text">Writings</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-teaching" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Teaching</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-teaching">    
        <li>
    <a class="dropdown-item" href="../../teaching/multi-calc-sp-26/multi-calc-sp-26.html">
 <span class="dropdown-text">Multivariable Calculus</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../teaching/pde-sp-26/pde-sp-26.html">
 <span class="dropdown-text">Partial Differential Equations</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="https://www.johnmyers-phd.com/book" target="_blank"> 
<span class="menu-text">Probabilistic Machine Learning</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.johnmyers-phd.com/sigalg" target="_blank"> 
<span class="menu-text">SigAlg</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/jmyers7/" target="_blank"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/john-myers-phd" target="_blank"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://bsky.app/profile/john-myers-phd.bsky.social" target="_blank"> <i class="bi bi-bluesky" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:jmmyers25@gmail.com"> <i class="bi bi-envelope-open-fill" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#tensor-spaces-as-hilbert-spaces" id="toc-tensor-spaces-as-hilbert-spaces" class="nav-link active" data-scroll-target="#tensor-spaces-as-hilbert-spaces">Tensor spaces as Hilbert spaces</a></li>
  <li><a href="#the-torch.einsum-function" id="toc-the-torch.einsum-function" class="nav-link" data-scroll-target="#the-torch.einsum-function">The <code>torch.einsum</code> function</a></li>
  <li><a href="#derivatives-jacobians-and-gradients" id="toc-derivatives-jacobians-and-gradients" class="nav-link" data-scroll-target="#derivatives-jacobians-and-gradients">Derivatives, Jacobians, and gradients</a></li>
  <li><a href="#enter-pytorch-computational-examples-of-derivatives" id="toc-enter-pytorch-computational-examples-of-derivatives" class="nav-link" data-scroll-target="#enter-pytorch-computational-examples-of-derivatives">Enter PyTorch: Computational examples of derivatives</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">PyTorch and derivatives: A mathematical perspective</h1>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 3, 2026</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="tensor-spaces-as-hilbert-spaces" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="tensor-spaces-as-hilbert-spaces">Tensor spaces as Hilbert spaces</h2>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-tensor" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1</strong></span> Let <span class="math inline">\(I\)</span> be a non-empty finite set that we call an <em>index set</em>, with elements <span class="math inline">\(i\in I\)</span> called <em>indices</em>. An <em><span class="math inline">\(I\)</span>-indexed tensor</em> is a function <span class="math display">\[
a : I \to \mathbb{R}, \quad i \mapsto a_i.
\]</span> We write <span class="math inline">\(\mathbb{R}^I\)</span> for the set of all <span class="math inline">\(I\)</span>-indexed tensors, and we call it the <em>tensor space</em> of <span class="math inline">\(I\)</span>-indexed tensors.</p>
</div>
</div>
</div>
</div>
<p>For example, if <span class="math inline">\(I = \{0,1,2\}\)</span>, then an <span class="math inline">\(I\)</span>-indexed tensor <span class="math inline">\(a\)</span> is just a selection of three real numbers:</p>
<div class="page-columns page-full"><p><span class="math display">\[
0 \mapsto a_0, \quad 1 \mapsto a_1, \quad 2 \mapsto a_2,
\]</span> </p><div class="no-row-height column-margin column-container"><span class="margin-aside">Notice the use of “<span class="math inline">\(0\)</span>-based indexing” here, which is standard in Python, but somewhat confusing for those accustomed to “<span class="math inline">\(1\)</span>-based indexing” in mathematics.</span></div></div>
<p>which we may write in vector form:</p>
<p><span class="math display">\[
a = \begin{bmatrix} a_0 \\ a_1 \\ a_2 \end{bmatrix}.
\]</span></p>
<p>If <span class="math inline">\(I = \{0,1\}\times \{0,1,2\}\)</span>, then an <span class="math inline">\(I\)</span>-indexed tensor <span class="math inline">\(b\)</span> is a selection of six real numbers:</p>
<p><span class="math display">\[
(0,0) \mapsto b_{00}, \quad (0,1) \mapsto b_{01}, \quad (0,2) \mapsto b_{02}, \quad (1,0) \mapsto b_{10}, \quad (1,1) \mapsto b_{11}, \quad (1,2) \mapsto b_{12},
\]</span></p>
<p>which we may write in matrix form:</p>
<p><span class="math display">\[
b = \begin{bmatrix} b_{00} &amp; b_{01} &amp; b_{02} \\ b_{10} &amp; b_{11} &amp; b_{12} \end{bmatrix}.
\]</span></p>
<p>Note that the decision to express the tensor <span class="math inline">\(a\)</span> as a column vector, rather than a row vector, and to express <span class="math inline">\(b\)</span> as a <span class="math inline">\(2\times 3\)</span> matrix, rather than a <span class="math inline">\(3\times 2\)</span> matrix, is a just matter of convention. The tensors themselves are just collections of numbers indexed by the elements of the index set <span class="math inline">\(I\)</span>, independent of any particular visual representation.</p>
<p>Tensors are <span class="math inline">\(\mathbb{R}\)</span>-valued <strong>functions</strong> first and foremost, and any sort of function space like <span class="math inline">\(\mathbb{R}^I\)</span> carries a vector space structure over <span class="math inline">\(\mathbb{R}\)</span>. Indeed, the operations are defined pointwise: for <span class="math inline">\(a, b \in \mathbb{R}^I\)</span> and <span class="math inline">\(c \in \mathbb{R}\)</span>, we define</p>
<p><span class="math display">\[
(a + b)_i = a_i + b_i, \quad (c a)_i = c a_i,
\]</span></p>
<p>for all <span class="math inline">\(i \in I\)</span>. The zero tensor <span class="math inline">\(0 \in \mathbb{R}^I\)</span> is defined by <span class="math inline">\(0_i = 0\)</span> for all <span class="math inline">\(i \in I\)</span>.</p>
<p>But more than this, tensor spaces also carry a natural inner product structure, which is also defined pointwise:</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-tensor-hilbert" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2</strong></span> Let <span class="math inline">\(I\)</span> be a non-empty finite index set, and consider the tensor space <span class="math inline">\(\mathbb{R}^i\)</span>. The <em>inner product</em> of two tensors <span class="math inline">\(a, b \in \mathbb{R}^I\)</span> is defined as <span class="math display">\[
\langle a, b \rangle = \sum_{i\in I} a_i b_i.
\]</span></p>
</div>
</div>
</div>
</div>
<p>When <span class="math inline">\(I\)</span> is a set of the form <span class="math inline">\(I = \{1,2,\ldots,m\}\)</span>, so that tensors in <span class="math inline">\(\mathbb{R}^I\)</span> may be represented as column vectors, the inner product is the familiar dot product of two vectors.</p>
<p>One can show easily that the inner product defined above really is an inner product in the precise mathematical sense: it is positive definite, symmetric, and bilinear. Thus, the tensor space <span class="math inline">\(\mathbb{R}^I\)</span> is a finite-dimensional Hilbert space.</p>
<p>The tensor spaces that one works with in practice—and in PyTorch in particular—have index sets of the form</p>
<p><span class="math display">\[
I = \{0,1,\ldots,m_1-1\} \times \{0,1,\ldots,m_2-1\} \times \cdots \times \{0,1,\ldots,m_k-1\},
\]</span></p>
<p>for some <span class="math inline">\(k\)</span> called the <em>rank</em> of the tensor, and some positive integers <span class="math inline">\(m_1, m_2, \ldots, m_k\)</span>. In this case, we will often write</p>
<p><span class="math display">\[
\mathbb{R}^{m_1 \times m_2 \times \cdots \times m_k}
\]</span></p>
<p>to stand for <span class="math inline">\(\mathbb{R}^I\)</span>, where <span class="math inline">\(I\)</span> is the index set above. The rank of a tensor is the number of indices required to specify its entries, and the <em>shape</em> of a tensor is the tuple <span class="math inline">\((m_1, m_2, \ldots, m_k)\)</span> that specifies the range of values for each index.</p>
<p>For example, we would write <span class="math inline">\(\mathbb{R}^3\)</span> to stand for <span class="math inline">\(\mathbb{R}^{\{0,1,2\}}\)</span>, which consists of rank-<span class="math inline">\(1\)</span> tensors of shape <span class="math inline">\((3)\)</span>, i.e., column vectors with three entries. Similarly, we would write <span class="math inline">\(\mathbb{R}^{2\times 3}\)</span> to stand for <span class="math inline">\(\mathbb{R}^{\{0,1\}\times \{0,1,2\}}\)</span>, which consists of rank-<span class="math inline">\(2\)</span> tensors of shape <span class="math inline">\((2,3)\)</span>, i.e., <span class="math inline">\(2\times 3\)</span> matrices. And so on.</p>
<p>Random integer-valued tensors of various shapes are easily generated in PyTorch using the <code>torch.randint</code> function. For example, the following code generates a random rank-<span class="math inline">\(4\)</span> tensor of shape <span class="math inline">\((2, 3, 4, 5)\)</span> with integer values between <span class="math inline">\(0\)</span> and <span class="math inline">\(9\)</span>:</p>
<div id="d8f656a6" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.randint(low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>, size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>The rank of a tensor is accessible in PyTorch as the <code>ndim</code> attribute, and the shape of a tensor is accessible as the <code>shape</code> attribute:</p>
<div id="6ff382cd" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The rank of the tensor is:"</span>, a.ndim)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The shape of the tensor is:"</span>, a.shape)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>The rank of the tensor is: 4
The shape of the tensor is: torch.Size([2, 3, 4, 5])</code></pre>
</div>
</div>
<p>The inner product on tensors spaces is implemented in PyTorch as the <code>torch.tensordot</code> function. For example, the following code block generates two random rank-<span class="math inline">\(2\)</span> tensors of shapce <span class="math inline">\((2,3)\)</span>, and then forms their inner product:</p>
<div id="f4561eea" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.randint(low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>, size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">3</span>))</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.randint(low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>, size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">3</span>))</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>inner_product <span class="op">=</span> torch.tensordot(a, b, dims<span class="op">=</span>a.ndim)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The first tensor is:</span><span class="ch">\n</span><span class="st">"</span>, a)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The second tensor is:</span><span class="ch">\n</span><span class="st">"</span>, b)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The inner product of the two tensors is:"</span>, inner_product)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>The first tensor is:
 tensor([[9, 6, 7],
        [6, 0, 9]])
The second tensor is:
 tensor([[5, 2, 9],
        [1, 7, 8]])
The inner product of the two tensors is: tensor(198)</code></pre>
</div>
</div>
<p>Just to check, let’s compute the inner product manually, and see if it mathches the result from <code>torch.tensordot</code>:</p>
<div id="451c5257" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> itertools <span class="im">import</span> product</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>I <span class="op">=</span> product(<span class="bu">range</span>(<span class="dv">2</span>), <span class="bu">range</span>(<span class="dv">3</span>))</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>manual_inner_product <span class="op">=</span> <span class="bu">sum</span>(a[i, j] <span class="op">*</span> b[i, j] <span class="cf">for</span> i, j <span class="kw">in</span> I)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The manually computed inner product is:"</span>, manual_inner_product)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>The manually computed inner product is: tensor(198)</code></pre>
</div>
</div>
<p>The reader may have noticed the parameter <code>dims=a.ndim</code> in the call to <code>torch.tensordot</code>. Its usage is explained well in the <a href="https://docs.pytorch.org/docs/stable/generated/torch.tensordot.html" target="_blank">PyTorch documentation</a>: If <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are tensors of rank <span class="math inline">\(m\)</span> and <span class="math inline">\(n\)</span>, respectively, then <code>torch.tensordot(a, b, dims=d)</code> produces a tensor <span class="math inline">\(r\)</span> of rank <span class="math inline">\(m+n-2d\)</span> by summing over the last <span class="math inline">\(d\)</span> indices of <span class="math inline">\(a\)</span> and the first <span class="math inline">\(d\)</span> indices of <span class="math inline">\(b\)</span>:</p>
<div class="page-columns page-full"><p><span class="math display">\[
r_{i_0,\ldots,i_{m+n-2d-1}} = \sum_{k_0,\ldots,k_{d-1}} a_{i_0,i_1,\ldots,i_{m-d-1},k_0,k_1,\ldots,k_{d-1}} b_{k_0,k_1,\ldots,k_{d-1},i_{m-d},\ldots,i_{m+n-2d-1}}.
\]</span> </p><div class="no-row-height column-margin column-container"><span class="margin-aside">Of course, in order for this to be well-defined, the last <span class="math inline">\(d\)</span> indices of <span class="math inline">\(a\)</span> and the first <span class="math inline">\(d\)</span> indices of <span class="math inline">\(b\)</span> must have the same range of values.</span></div></div>
<p>To produce the inner product of <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, as specified above, we must sum the tensors over <em>all</em> their indices, which explains the use of <code>dims=a.ndim</code> in our call to <code>torch.tensordot</code>. In this case, <span class="math inline">\(m=n=2\)</span> and <span class="math inline">\(d=2\)</span>, so that the rank of the resulting tensor is <span class="math inline">\(m+n-2d = 0\)</span>, i.e., a scalar.</p>
</section>
<section id="the-torch.einsum-function" class="level2">
<h2 class="anchored" data-anchor-id="the-torch.einsum-function">The <code>torch.einsum</code> function</h2>
<p>An even more flexible and general way to compute tensors of the form <span class="math inline">\(r\)</span> described above is to use the <code>torch.einsum</code> function, which implements a form of <a href="https://en.wikipedia.org/wiki/Einstein_notation" target="_blank">Einstein summation notation</a>. For example, lets suppose that we have two tensors of the form</p>
<p><span class="math display">\[
a_{ijk} \quad \text{and} \quad b_{pqrs},
\]</span></p>
<p>by which we mean that <span class="math inline">\(a\)</span> is rank <span class="math inline">\(3\)</span> and <span class="math inline">\(b\)</span> is rank <span class="math inline">\(4\)</span>. We suppose further that the range of values of <span class="math inline">\(i\)</span> matches the range of values of <span class="math inline">\(q\)</span>, and the range of values of <span class="math inline">\(j\)</span> matches the range of values of <span class="math inline">\(s\)</span>. For example, the following code block produces two random integer-valued tensors with these properties:</p>
<div id="4874147c" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The following index ranges match: i ↔ q and j ↔ s</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.randint(low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>, size<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">4</span>))  <span class="co"># indices = (i,j,k)</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.randint(low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>, size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">4</span>, <span class="dv">3</span>))  <span class="co"># indices = (p,q,r,s)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="66356e16" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>einsum_result <span class="op">=</span> torch.einsum(<span class="st">"ijk,pirj"</span>, a, b)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The result of the Einstein summation is:</span><span class="ch">\n</span><span class="st">"</span>, einsum_result)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>The result of the Einstein summation is:
 tensor([[[248, 424, 403, 309],
         [290, 411, 310, 289]],

        [[234, 352, 317, 162],
         [136, 315, 323, 302]],

        [[232, 301, 296, 205],
         [162, 281, 209, 236]],

        [[298, 408, 379, 265],
         [265, 451, 311, 303]]])</code></pre>
</div>
</div>
</section>
<section id="derivatives-jacobians-and-gradients" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="derivatives-jacobians-and-gradients">Derivatives, Jacobians, and gradients</h2>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-derivative" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3</strong></span> Let <span class="math inline">\(\mathcal{H}\)</span> and <span class="math inline">\(\mathcal{K}\)</span> be two finite-dimensional Hilbert spaces. The <em>derivative</em> of a function <span class="math inline">\(f: \mathcal{H} \to \mathcal{K}\)</span> at a point <span class="math inline">\(x \in \mathcal{H}\)</span> and in the direction <span class="math inline">\(v \in \mathcal{H}\)</span> is defined as <span class="math display">\[
f'(x)(v) = \lim_{t \to 0} \frac{f(x + tv) - f(x)}{t},
\]</span> provided the limit exists. If the derivative exists for all <span class="math inline">\(x \in \mathcal{H}\)</span> and <span class="math inline">\(v \in \mathcal{H}\)</span>, we say that <span class="math inline">\(f\)</span> is <em>differentiable</em>.</p>
</div>
</div>
</div>
</div>
<div class="page-columns page-full"><p>Technically, the type of differentiability I’ve defined here is called <a href="https://en.wikipedia.org/wiki/Gateaux_derivative" target="_blank"><em>Gateaux differentiability</em></a>, and it is a weaker condition than the more commonly used notion of <a href="https://en.wikipedia.org/wiki/Fr%C3%A9chet_derivative" target="_blank"><em>Fréchet differentiability</em></a>. Roughly speaking, a function is Fréchet differentiable at a point if it can be well approximated by a linear function in a neighborhood of that point, whereas Gateaux differentiability only requires the existence of directional derivatives. However, for our purposes in this post, we will implicitly assume that all our functions are Fréchet differentiable, in which case the derivative (as defined above) of a differentiable function yields a linear map <span class="math inline">\(f'(x): \mathcal{H} \to \mathcal{K}\)</span> with <span class="math inline">\(v \mapsto f'(x)(v)\)</span>.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">There are conditions that, when added to Gateaux differentiability, ensure that the function is also Fréchet differentiable. For example, if the <em>partial derivatives</em> of a Gateaux differentiable function are continuous (see below), then the function is also Fréchet differentiable.</span></div></div>
<p>It is always the case in applications that fixed orthonormal bases of the Hilbert spaces <span class="math inline">\(\mathcal{H}\)</span> and <span class="math inline">\(\mathcal{K}\)</span> are at hand. If <span class="math inline">\(\{\epsilon_i\}\)</span> is the fixed basis for <span class="math inline">\(\mathcal{K}\)</span>, and if <span class="math inline">\(f: \mathcal{H} \to \mathcal{K}\)</span> is a function, then we have real-valued <em>component functions</em></p>
<p><span class="math display">\[
f_i: \mathcal{H} \to \mathbb{R}, \quad f_i(x) = \langle f(x), \epsilon_i \rangle,
\]</span></p>
<p>one for each basis vector <span class="math inline">\(\epsilon_i\)</span>. One may show that if <span class="math inline">\(f\)</span> is differentiable, then so too are each of the component functions <span class="math inline">\(f_i\)</span>, and moreover, we have the fundamental link between the derivative of <span class="math inline">\(f\)</span> and the derivatives of its component functions:</p>
<p><span id="eq-component-derivative"><span class="math display">\[
f_i'(x)(v) = \langle f'(x)(v), \epsilon_i \rangle,
\tag{1}\]</span></span></p>
<p>for all <span class="math inline">\(x, v \in \mathcal{H}\)</span> and all <span class="math inline">\(i\)</span>. This leads us to the following central definition:</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-partial-derivative" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4</strong></span> Let <span class="math inline">\(f: \mathcal{H} \to \mathcal{K}\)</span> be a differentiable function between two finite-dimensional Hilbert spaces, and let <span class="math inline">\(\{e_j\}\)</span> and <span class="math inline">\(\{\epsilon_i\}\)</span> be orthonormal bases for <span class="math inline">\(\mathcal{H}\)</span> and <span class="math inline">\(\mathcal{K}\)</span>, respectively. The <em>partial derivative</em> of the <span class="math inline">\(i\)</span>-th component function <span class="math inline">\(f_i\)</span> at a point <span class="math inline">\(x \in \mathcal{H}\)</span> with respect to the basis vector <span class="math inline">\(e_j\)</span> is defined as <span class="math display">\[
\frac{\partial f_i}{\partial e_j}(x) = f_i'(x)(e_j).
\]</span></p>
</div>
</div>
</div>
</div>
<p>Invoking equation (<a href="#eq-component-derivative" class="quarto-xref">1</a>), we see that the partial derivative can be equivalently expressed as</p>
<p><span class="math display">\[
\frac{\partial f_i}{\partial e_j}(x) = \left\langle f'(x)(e_j), \epsilon_i \right\rangle.
\]</span></p>
<p>In the case that <span class="math inline">\(f\)</span> is real-valued, so that <span class="math inline">\(\mathcal{K} = \mathbb{R}\)</span>, we will <em>always</em> take the basis of <span class="math inline">\(\mathbb{R}\)</span> to be <span class="math inline">\(\{1\}\)</span>, and so the partial derivatives of a real-valued function <span class="math inline">\(f\)</span> at a point <span class="math inline">\(x\)</span> with respect to the basis vectors <span class="math inline">\(\{e_j\}\)</span> of <span class="math inline">\(\mathcal{H}\)</span> are given by</p>
<p><span class="math display">\[
\frac{\partial f}{\partial e_j}(x) = \langle f'(x)(e_j), 1 \rangle = f'(x)(e_j).
\]</span></p>
<p>The importance of the partial derivatives is that they are the entries in matrix representations of derivatives:</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-jacobian" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 5</strong></span> Let <span class="math inline">\(f: \mathcal{H} \to \mathcal{K}\)</span> be a differentiable function between two finite-dimensional Hilbert spaces, and let <span class="math inline">\(\{e_j\}\)</span> and <span class="math inline">\(\{\epsilon_i\}\)</span> be orthonormal bases for <span class="math inline">\(\mathcal{H}\)</span> and <span class="math inline">\(\mathcal{K}\)</span>, respectively. The <em>Jacobian matrix</em> of <span class="math inline">\(f\)</span> at a point <span class="math inline">\(x \in \mathcal{H}\)</span> is the matrix <span class="math display">\[
Jf(x)_{ij} = \frac{\partial f_i}{\partial e_j}(x).
\]</span></p>
</div>
</div>
</div>
</div>
<p>One must take care in interpreting a Jacobian “matrix” as a matrix in the usual way, since the index sets for the bases <span class="math inline">\(\{e_j\}\)</span> and <span class="math inline">\(\{\epsilon_i\}\)</span> may be more complicated than just <span class="math inline">\(\{1, \ldots, n\}\)</span> and <span class="math inline">\(\{1, \ldots, m\}\)</span>, as is the case when <span class="math inline">\(\mathcal{H}\)</span> and <span class="math inline">\(\mathcal{K}\)</span> are tensor spaces like <span class="math inline">\(\mathbb{R}^{m\times n}\)</span> or <span class="math inline">\(\mathbb{R}^{m\times n \times p}\)</span>.</p>
<p>The sense in which the Jacobian matrix <span class="math inline">\(Jf(x)\)</span> represents the derivative <span class="math inline">\(f'(x)\)</span> may be described as follows. Suppose given a vector <span class="math inline">\(v\in \mathcal{H}\)</span>, and perform a Fourier expansion relative to the basis <span class="math inline">\(\{e_j\}\)</span>:</p>
<p><span class="math display">\[
v = \sum_j \langle v, e_j \rangle e_j = \sum_j v_j e_j,
\]</span></p>
<p>where <span class="math inline">\(v_j = \langle v, e_j \rangle\)</span>. Then, for each <span class="math inline">\(j\)</span>, we also have the Fourier expansion of <span class="math inline">\(f'(x)(e_j)\)</span> relative to the basis <span class="math inline">\(\{\epsilon_i\}\)</span>:</p>
<p><span class="math display">\[
f'(x)(e_j) = \sum_i \langle f'(x)(e_j), \epsilon_i \rangle \epsilon_i = \sum_i \frac{\partial f_i}{\partial e_j}(x) \epsilon_i.
\]</span></p>
<p>Thus:</p>
<p><span id="eq-jacobian-representation"><span class="math display">\[
f'(x)(v) = \sum_j v_j f'(x)(e_j) = \sum_i \left[ \sum_j v_j \frac{\partial f_i}{\partial e_j}(x) \right] \epsilon_i.
\tag{2}\]</span></span></p>
<p>The reader will notice the familiar matrix multiplication pattern in the square brackets. If, in particular, the indices <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> range over <span class="math inline">\(\{1, \ldots, m\}\)</span> and <span class="math inline">\(\{1, \ldots, n\}\)</span>, respectively, then the Jacobian matrix <span class="math inline">\(Jf(x)\)</span> is an <span class="math inline">\(m\times n\)</span> matrix, and the expression in the square brackets is just the <span class="math inline">\(i\)</span>-th entry of the column vector</p>
<p><span class="math display">\[
\begin{bmatrix}
\sum_j v_j \frac{\partial f_1}{\partial e_j}(x) \\
\vdots \\
\sum_j v_j \frac{\partial f_m}{\partial e_j}(x)
\end{bmatrix}=\begin{bmatrix} \frac{\partial f_1}{\partial e_1}(x) &amp; \cdots &amp; \frac{\partial f_1}{\partial e_n}(x) \\ \vdots &amp; \ddots &amp; \vdots \\ \frac{\partial f_m}{\partial e_1}(x) &amp; \cdots &amp; \frac{\partial f_m}{\partial e_n}(x) \end{bmatrix} \begin{bmatrix} v_1 \\ \vdots \\ v_n \end{bmatrix}.
\]</span></p>
<p>With derivatives and Jacobians in hand, we now move toward defining the gradient, which requires the Riesz Representation Theorem. To state it, however, we need to first introduce the notion of the <em>dual</em> of a (finite-dimensional) Hilbert space. This is the vector space <span class="math inline">\(\mathcal{H}^*\)</span> of all linear functionals <span class="math inline">\(\phi: \mathcal{H} \to \mathbb{R}\)</span>, where a <em>linear functional</em> is a linear map from <span class="math inline">\(\mathcal{H}\)</span> to <span class="math inline">\(\mathbb{R}\)</span>. Its vector space structure is given by pointwise addition and scalar multiplication, so that for <span class="math inline">\(\phi, \psi \in \mathcal{H}^*\)</span> and <span class="math inline">\(a\in \mathbb{R}\)</span>, we have that</p>
<p><span class="math display">\[
(\phi + \psi)(v) = \phi(v) + \psi(v)
\]</span></p>
<p>and</p>
<p><span class="math display">\[(a\phi)(v) = a\phi(v)
\]</span></p>
<p>for all <span class="math inline">\(v \in \mathcal{H}\)</span>. In fact, these definitions work for <em>any</em> vector space, not just Hilbert spaces. But the interest in Hilbert spaces is that they have a built-in mechanism for producing linear functionals from vectors. Indeed, for each <span class="math inline">\(v \in \mathcal{H}\)</span>, we can define a linear functional</p>
<p><span class="math display">\[
v^\ast: \mathcal{H} \to \mathbb{R}, \quad v^\ast(w) = \langle v, w \rangle,
\]</span></p>
<p>which is sometimes called the <em>covector</em> associated to <span class="math inline">\(v\)</span>. Linearity of the inner product in the second argument ensures that the covector is a linear functional, and so <span class="math inline">\(v^\ast \in \mathcal{H}^*\)</span>. Moreover, the mapping <span class="math inline">\(v \mapsto v^\ast\)</span> is a linear map from <span class="math inline">\(\mathcal{H}\)</span> to <span class="math inline">\(\mathcal{H}^*\)</span>, in the sense that it preserves vector addition and scalar multiplication.</p>
<p>The Riesz Representation Theorem states that <em>every</em> linear functional on a finite-dimensional Hilbert space arises as an inner product against a unique vector, called its <em>Riesz representation</em>:</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-riesz" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 (Riesz Representation Theorem — finite-dimensional version)</strong></span> Let <span class="math inline">\(\mathcal{H}\)</span> be a finite-dimensional Hilbert space. For every linear functional <span class="math inline">\(\phi: \mathcal{H} \to \mathbb{R}\)</span>, there exists a unique vector <span class="math inline">\(v_\phi \in \mathcal{H}\)</span> such that <span class="math inline">\(\phi = v_\phi^\ast\)</span>. In particular, the mapping <span class="math inline">\(v\mapsto v^\ast\)</span> is a linear isomorphism from <span class="math inline">\(\mathcal{H}\)</span> to <span class="math inline">\(\mathcal{H}^*\)</span>.</p>
</div>
</div>
</div>
</div>
<p>Using the Riesz isomorphism from <span class="math inline">\(\mathcal{H}\)</span> to <span class="math inline">\(\mathcal{H}^\ast\)</span>, we can transport the inner product from <span class="math inline">\(\mathcal{H}\)</span> to <span class="math inline">\(\mathcal{H}^*\)</span>, and thus equip <span class="math inline">\(\mathcal{H}^*\)</span> with the structure of a Hilbert space. In particular, for <span class="math inline">\(\phi, \psi \in \mathcal{H}^*\)</span>, we can define their inner product as</p>
<p><span class="math display">\[
\langle \phi, \psi \rangle = \langle v_\phi, v_\psi \rangle.
\]</span></p>
<p>When the dual space <span class="math inline">\(\mathcal{H}^\ast\)</span> is equipped with this inner product, we call it the <em>dual Hilbert space</em> of <span class="math inline">\(\mathcal{H}\)</span>. The Riesz isomorphism is then an <em>isometric</em> isomorphism between the Hilbert space <span class="math inline">\(\mathcal{H}\)</span> and its dual Hilbert space <span class="math inline">\(\mathcal{H}^*\)</span>.</p>
<p>We have the mapping <span class="math inline">\((-)^\ast: \mathcal{H} \to \mathcal{H}^*\)</span> that acts on vectors by sending <span class="math inline">\(v\)</span> to the covector <span class="math inline">\(v^\ast\)</span>. A similar mapping acts on a linear map <span class="math inline">\(T: \mathcal{H} \to \mathcal{K}\)</span>, where <span class="math inline">\(\mathcal{H}\)</span> and <span class="math inline">\(\mathcal{K}\)</span> are finite-dimensional Hilbert spaces. This is the <em>adjoint</em> of <span class="math inline">\(T\)</span>, denoted by <span class="math inline">\(T^\ast: \mathcal{K} \to \mathcal{H}\)</span>, and it is defined as the unique linear map such that</p>
<p><span class="math display">\[
\langle T(v), w \rangle = \langle v, T^\ast(w) \rangle,
\]</span></p>
<p>for all <span class="math inline">\(v\in \mathcal{H}\)</span> and <span class="math inline">\(w \in \mathcal{K}\)</span>. Notice, in particular, that if we have orthonormal bases <span class="math inline">\(\{e_j\}\)</span> and <span class="math inline">\(\{\epsilon_i\}\)</span> for <span class="math inline">\(\mathcal{H}\)</span> and <span class="math inline">\(\mathcal{K}\)</span>, respectively, then</p>
<p><span class="math display">\[
\langle T(e_j), \epsilon_i \rangle = \langle e_j, T^\ast(\epsilon_i) \rangle,
\]</span></p>
<p>so that the <span class="math inline">\(ij\)</span>-th entry of the “matrix” representation of <span class="math inline">\(T\)</span> relative to these bases is equal to the <span class="math inline">\(ji\)</span>-th entry of the “matrix” representation of <span class="math inline">\(T^\ast\)</span> relative to the same bases. Again, we must take care in interpreting these “matrices” as matrices in the usual way—just as above when we discussed Jacobian matrices—since the index sets for the bases <span class="math inline">\(\{e_j\}\)</span> and <span class="math inline">\(\{\epsilon_i\}\)</span> may be more complicated than just <span class="math inline">\(\{1, \ldots, n\}\)</span> and <span class="math inline">\(\{1, \ldots, m\}\)</span>.</p>
<p>We now obtain the <em>gradient</em> by smacking the derivative with the Riesz theorem:</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-gradient" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 6</strong></span> Let <span class="math inline">\(\mathcal{H}\)</span> be a finite-dimensional Hilbert space, and let <span class="math inline">\(f: \mathcal{H} \to \mathbb{R}\)</span> be a differentiable function. The <em>gradient</em> of <span class="math inline">\(f\)</span> at a point <span class="math inline">\(x\in \mathcal{H}\)</span> is the Riesz representation of the linear functional <span class="math inline">\(f'(x)\in \mathcal{H}^\ast\)</span>, denoted by <span class="math inline">\(\nabla f(x) \in \mathcal{H}\)</span>. In particular, we have that <span class="math display">\[
f'(x)(v) = \left\langle \nabla f(x), v \right\rangle,
\]</span> for all <span class="math inline">\(v \in \mathcal{H}\)</span>.</p>
</div>
</div>
</div>
</div>
<p>Do notice that the gradient is only defined for real-valued functions, not functions with values in a general Hilbert space.</p>
<p>Existence and uniqueness of the gradient follow from the general <a href="https://en.wikipedia.org/wiki/Riesz_representation_theorem" target="_blank">Riesz representation theorem</a>, though in the present finite-dimensional setting, both can be demonstrated easily by direct construction. Indeed, if <span class="math inline">\(\{e_j\}\)</span> is an orthonormal basis for <span class="math inline">\(\mathcal{H}\)</span>, and if we <em>assume</em> that <span class="math inline">\(\nabla f(x)\)</span> exists with the stated property, then for each <span class="math inline">\(e_j\)</span>, we have that</p>
<p><span class="math display">\[
\nabla f(x) = \sum_j \langle \nabla f(x), e_j \rangle e_j = \sum_j f'(x)(e_j) e_j,
\]</span></p>
<p>which shows that the gradient is unique if it exists. To <em>prove</em> that it exists, we can simply define <span class="math inline">\(\nabla f(x)\)</span> to be the vector given by the right-hand side of the above equation, and then verify that it satisfies the required property. (By the way, this argument is essentially the standard proof of the Riesz representation theorem as stated above.) Furthermore, since <span class="math inline">\(f'(x)(e_j) = \frac{\partial f}{\partial e_j}(x)\)</span>, the Fourier expansion of the gradient relative to the basis <span class="math inline">\(\{e_j\}\)</span> is given by</p>
<p><span class="math display">\[
\nabla f(x) = \sum_j \frac{\partial f}{\partial e_j}(x) e_j,
\]</span></p>
<p>which should be familiar to anyone who has taken a course in multivariable calculus.</p>
<p>One of the most useful properties of the gradient is that it “points” in the direction of greatest increase of the function. This is made precise in the following result:</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-gradient-max-increase" class="theorem">
<p><span class="theorem-title"><strong>Theorem 2</strong></span> Let <span class="math inline">\(\mathcal{H}\)</span> be a finite-dimensional Hilbert space, let <span class="math inline">\(f: \mathcal{H} \to \mathbb{R}\)</span> be a differentiable function, and suppose the gradient <span class="math inline">\(\nabla f(x)\)</span> is nonzero at a point <span class="math inline">\(x\in \mathcal{H}\)</span>. Suppose we consider the value of the derivative <span class="math inline">\(f'(x)(v)\)</span> as a function of unit vectors <span class="math inline">\(v \in \mathcal{H}\)</span>. Then:</p>
<ol type="1">
<li><p>The derivative is maximized at <span class="math inline">\(v = \nabla f(x)/\|\nabla f(x)\|\)</span>, and the maximum value is <span class="math inline">\(\|\nabla f(x)\|\)</span>.</p></li>
<li><p>The derivative is minimized at <span class="math inline">\(v = -\nabla f(x)/\|\nabla f(x)\|\)</span>, and the minimum value is <span class="math inline">\(-\|\nabla f(x)\|\)</span>.</p></li>
</ol>
</div>
</div>
</div>
</div>
<div class="no-row-height column-margin column-container"><span class="margin-aside callout-margin-content callout-margin-content-simple">Note that this statement of the extremizing property of the gradient makes no reference to any “angles” between vectors, that are often invoked in the usual geometric explanation of this property.</span></div><div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Proof.
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The proof uses the <a href="https://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality" target="_blank">Cauchy-Schwarz inequality</a>, which states that for all <span class="math inline">\(v, w \in \mathcal{H}\)</span>, we have that <span class="math display">\[
|\langle v, w \rangle| \leq \|v\| \|w\|,
\]</span></p>
<p>with equality if and only if <span class="math inline">\(v\)</span> and <span class="math inline">\(w\)</span> are linearly dependent. Applying this to the inner product <span class="math inline">\(\langle \nabla f(x), v \rangle\)</span>, where <span class="math inline">\(v\)</span> is a unit vector, we get that</p>
<p><span class="math display">\[
|f'(x)(v)| = |\langle \nabla f(x), v \rangle| \leq \|\nabla f(x)\| \|v\| = \|\nabla f(x)\|,
\]</span></p>
<p>which may be written as the compound inequality</p>
<p><span class="math display">\[
- \|\nabla f(x)\| \leq f'(x)(v) \leq \|\nabla f(x)\|,
\]</span></p>
<p>with equality at one of the two ends if and only if <span class="math inline">\(v\)</span> is a scalar multiple of <span class="math inline">\(\nabla f(x)\)</span>. It remains only to note that</p>
<p><span class="math display">\[
f'(x)(\pm \nabla f(x)) = \langle \nabla f(x), \pm\nabla f(x) \rangle = \pm \|\nabla f(x)\|^2,
\]</span></p>
<p>which finishes the proof.</p>
</div>
</div>
</div>
<p>The gradient may be obtained through the adjoint action of the derivative, as stated in the following important result:</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-gradient-adjoint" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3</strong></span> Let <span class="math inline">\(\mathcal{H}\)</span> be a finite-dimensional Hilbert space, and let <span class="math inline">\(f: \mathcal{H} \to \mathbb{R}\)</span> be a differentiable function. Then the gradient of <span class="math inline">\(f\)</span> at a point <span class="math inline">\(x\in \mathcal{H}\)</span> is given by the adjoint of the derivative of <span class="math inline">\(f\)</span> at <span class="math inline">\(x\)</span> applied to the scalar <span class="math inline">\(1\)</span>: <span class="math display">\[
\nabla f(x) = f'(x)^\ast(1).
\]</span></p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Proof.
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The proof is a one-liner. For any <span class="math inline">\(v \in \mathcal{H}\)</span>, we first observe that</p>
<p><span class="math display">\[
f'(x)(v) = \langle 1, f'(x)(v) \rangle =  \langle f'(x)^\ast(1), v \rangle,
\]</span></p>
<p>and then we invoke the uniqueness of the Riesz representation to conclude that <span class="math inline">\(\nabla f(x) = f'(x)^\ast(1)\)</span>.</p>
</div>
</div>
</div>
<p>We work toward ending this long section by studying how the adjoint and derivative operations interact with function composition. Fortunately, both stories could not be simpler. For the adjoint, we have that</p>
<p><span class="math display">\[
(S\circ T)^\ast = T^\ast \circ S^\ast,
\]</span></p>
<p>for linear maps <span class="math inline">\(\mathcal{H} \xrightarrow{T} \mathcal{K} \xrightarrow{S} \mathcal{L}\)</span> on finite-dimensional Hilbert spaces. The proof uses the uniqueness of the adjoint. For any <span class="math inline">\(v \in \mathcal{H}\)</span> and <span class="math inline">\(w \in \mathcal{L}\)</span>, we have that</p>
<p><span class="math display">\[
\langle (S\circ T)(v), w \rangle = \langle S(T(v)), w \rangle = \langle T(v), S^\ast(w) \rangle = \langle v, T^\ast(S^\ast(w)) \rangle,
\]</span></p>
<p>so that <span class="math inline">\((S\circ T)^\ast(w) = T^\ast(S^\ast(w))\)</span>, and thus <span class="math inline">\((S\circ T)^\ast = T^\ast \circ S^\ast\)</span>.</p>
<p>For derivatives and composition, we have:</p>
<div class="callout callout-style-simple callout-tip no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-chain-rule" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4 (Chain Rule)</strong></span> Let <span class="math inline">\(\mathcal{H} \xrightarrow{f} \mathcal{K} \xrightarrow{g} \mathcal{L}\)</span> be differentiable functions on finite-dimensional Hilbert spaces. Then the composition <span class="math inline">\(g\circ f: \mathcal{H} \to \mathcal{L}\)</span> is differentiable, and its derivative at a point <span class="math inline">\(x\in \mathcal{H}\)</span> is given by the composition of the derivatives of <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> at the appropriate points:  <span class="math display">\[
(g\circ f)'(x) = g'(f(x)) \circ f'(x).
\]</span></p>
</div>
</div>
</div>
</div>
<div class="no-row-height column-margin column-container"><span class="margin-aside callout-margin-content callout-margin-content-simple">We do not prove the Chain Rule here. The interested reader may consult Section 2.3 of <span class="citation" data-cites="Coleman2012">[<a href="#ref-Coleman2012" role="doc-biblioref">1</a>]</span>.</span></div></section>
<section id="enter-pytorch-computational-examples-of-derivatives" class="level2">
<h2 class="anchored" data-anchor-id="enter-pytorch-computational-examples-of-derivatives">Enter PyTorch: Computational examples of derivatives</h2>
<p>Wowza. A hearty slap on the back for ya’, if you endured the previous section and have made it this far. That was all very abstract, very theoretical, and very <em>mathematical</em> (some of you might not view that last adjective as a compliment). But while it’s important for a person to have a solid grasp on the theory, it’s pretty useless if they cannot apply it in practice. In this section, I’ll show you how all that theory can be beautifully illuminated by working through concrete examples using PyTorch.</p>
<p>Let’s consider a differentiable function <span class="math display">\[
f: \mathbb{R}^{m\times n} \to \mathbb{R}^{p\times q}.
\]</span></p>
<p>Given two vectors <span class="math inline">\(x\)</span> and <span class="math inline">\(v\)</span> in <span class="math inline">\(\mathbb{R}^{m\times n}\)</span>, we can express the vector <span class="math inline">\(f'(x)(v)\in \mathbb{R}^{p\times q}\)</span> as a Fourier expansion relative to the standard orthonormal basis vectors <span class="math inline">\(\epsilon_{ij}\in \mathbb{R}^{p\times q}\)</span> identified in the previous section:</p>
<p><span class="math display">\[
f'(x)(v) = \sum_{i,j} \left\langle f'(x)(v), \epsilon_{ij} \right\rangle \epsilon_{ij}.  \tag*{$\begin{Bmatrix} 0\leq i &lt; p \\ 0 \leq j &lt; q \end{Bmatrix}$}
\]</span></p>
<p>Similarly, we can write</p>
<p><span class="math display">\[
v = \sum_{k,l} \left\langle v, e_{kl} \right\rangle e_{kl} = \sum_{k,l} v_{kl} e_{kl}, \tag*{$\begin{Bmatrix} 0\leq k &lt; m \\ 0 \leq l &lt; n \end{Bmatrix}$}
\]</span></p>
<p>where <span class="math inline">\(e_{kl}\)</span> are the standard orthonormal basis vectors of <span class="math inline">\(\mathbb{R}^{m\times n}\)</span> and <span class="math inline">\(v_{kl} = \langle v, e_{kl} \rangle\)</span>. Substituting this into the expression for <span class="math inline">\(f'(x)(v)\)</span> and using linearity, we get that:</p>
<p><span class="math display">\[
f'(x)(v) = \sum_{k,l} v_{kl} f'(x)(e_{kl}). \tag*{$\begin{Bmatrix} 0\leq k &lt; m \\ 0 \leq l &lt; n \end{Bmatrix}$}
\]</span></p>
<p>Therefore, we can write</p>
<p><span class="math display">\[
f'(x)(v) = \sum_{i,j} \left[ \sum_{k,l}  v_{kl} \left\langle f'(x)(e_{kl}), \epsilon_{ij} \right\rangle \right]\epsilon_{ij}. \tag*{$\begin{Bmatrix} 0\leq i &lt; p \\ 0 \leq j &lt; q \\ 0 \leq k &lt; m \\ 0 \leq l &lt; n \end{Bmatrix}$}
\]</span></p>
<p>But</p>
<p><span class="math display">\[
\left\langle f'(x)(e_{kl}), \epsilon_{ij} \right\rangle = \frac{\partial f_{ij}}{\partial x_{kl}}(x),
\]</span></p>
<p>and so this last equation becomes</p>
<p><span class="math display">\[
f'(x)(v) = \sum_{i,j} \left[ \sum_{k,l}  v_{kl} \frac{\partial f_{ij}}{\partial x_{kl}}(x) \right]\epsilon_{ij}.  \tag*{$\begin{Bmatrix} 0\leq i &lt; p \\ 0 \leq j &lt; q \\ 0 \leq k &lt; m \\ 0 \leq l &lt; n \end{Bmatrix}$}
\]</span></p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body" data-entry-spacing="0" role="list">
<div id="ref-Coleman2012" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">Coleman, R., <em>Calculus on normed vector spaces</em>, Universitext, Springer, 2012.</div>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/johnmyers-phd\.com");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>