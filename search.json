[
  {
    "objectID": "writings.html",
    "href": "writings.html",
    "title": "john myers, ph.d.",
    "section": "",
    "text": "Einstein does deep learning\n\n\n\nPython\n\nPyTorch\n\nDeep Learning\n\nNeural networks\n\nTensors\n\nLinear algebra\n\n\n\n\n\n\n\n\n\nOct 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is information theory? (with SciPy!)\n\n\n\nPython\n\nSciPy\n\nInformation theory\n\nEntropy\n\nProbability\n\nSurprisal\n\n\n\n\n\n\n\n\n\nSep 30, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nPyTorch can do your calculus homework\n\n\n\nPython\n\nPyTorch\n\nDeep Learning\n\nNeural networks\n\nTensors\n\nCalculus\n\nLinear algebra\n\n\n\n\n\n\n\n\n\nSep 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n‚ÄúShiny‚Äù Central Limit Theorem\n\n\n\nR\n\nShiny\n\nPython\n\nSciPy\n\nReticulate\n\nInteractive\n\nProbability\n\nStatistics\n\nCentral Limit Theorem\n\n\n\n\n\n\n\n\n\nSep 25, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nCookies and Gaussians\n\n\n\nR\n\nProbability\n\nStatistics\n\nProbabilistic graphical models\n\n\n\n\n\n\n\n\n\nSep 22, 2025\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "courses/25-fa-analysis.html",
    "href": "courses/25-fa-analysis.html",
    "title": "mat347 analysis, fall 2025",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Curabitur nec eros eget nisl posuere fermentum. Phasellus vitae augue nec justo commodo gravida. Vivamus euismod, nisi a tristique dictum, sapien libero tempor nulla, sit amet dignissim justo elit sit amet lectus. Sed euismod risus a felis facilisis, in tincidunt purus luctus."
  },
  {
    "objectID": "posts/ein-dl/index.html",
    "href": "posts/ein-dl/index.html",
    "title": "Einstein does deep learning",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Curabitur nec eros eget nisl posuere fermentum. Phasellus vitae augue nec justo commodo gravida."
  },
  {
    "objectID": "posts/scipy-info/index.html",
    "href": "posts/scipy-info/index.html",
    "title": "What is information theory? (with SciPy!)",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Curabitur nec eros eget nisl posuere fermentum. Phasellus vitae augue nec justo commodo gravida."
  },
  {
    "objectID": "posts/pytorch-calc/index.html",
    "href": "posts/pytorch-calc/index.html",
    "title": "PyTorch can do your calculus homework",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Curabitur nec eros eget nisl posuere fermentum. Phasellus vitae augue nec justo commodo gravida."
  },
  {
    "objectID": "posts/mixture/index.html",
    "href": "posts/mixture/index.html",
    "title": "Cookies and Gaussians",
    "section": "",
    "text": "You‚Äôre a data scientist at a cookie convention. What do you do? Survey the participants and fit a Gaussian mixture model, of course. üç™ üòã\n\nExploratory cookie analysis\nYou surveyed 1,000 cookie convention attendees to find out just how many cookies they could devour in a single day. Naturally, being the conscientious data scientist you are, you fired up Python and loaded the results into a NumPy array to crunch some summary statistics:\n\n\nCode\ndata = np.load(\"cookie_data.npy\")\ndata_count = len(data)\ndata_mean = np.mean(data)\ndata_sd = np.std(data)\n\nprint(f\"There are {data_count} observations in the data.\")\nprint(f\"The first five observations are {data[:5]}.\")\nprint(f\"The data mean is {data_mean:.2f}, while the standard deviation is {data_sd:.2f}.\")\n\n\nThere are 1000 observations in the data.\nThe first five observations are [15. 20. 16. 16. 11.].\nThe data mean is 14.63, while the standard deviation is 3.42.\n\n\nOf course, every good data scientist wants to see the data, so you whip up a Seaborn histogram to get the full cookie picture:\n\n\nCode\nsns.histplot(data=data, color=yellow, alpha=1, ec=grey, zorder=2)\nplt.xlabel('x = number of cookies')\nplt.ylabel('count')\nplt.title('cookie data')\nplt.show()\n\n\n\n\n\n\n\n\n\nThree clusters! One has a peak around 10 cookies, the second around 15, and the third has a peak near a whopping 21 cookies. Clearly, there are distinct groups of cookie lovers here, which makes this dataset is a perfect candidate for a Gaussian mixture model (GMM), which seeks to identify clusters in data.\n\n\nFitting a GMM in scikit-learn\n\nfrom sklearn.mixture import GaussianMixture\n\nX = data.reshape(-1, 1)\n\ngmm = GaussianMixture(n_components=3, random_state=42)\ngmm.fit(X)\n\nmeans = gmm.means_.flatten()\nstds = np.sqrt(gmm.covariances_).flatten()\nweights = gmm.weights_\nparams = [{\"loc\": mu, \"scale\": sigma} for mu, sigma in zip(means, stds)]\n\nprint(\"Means:\", means)\nprint(\"Standard deviations:\", stds)\nprint(\"Weights:\", weights)\n\nMeans: [10.15407874 20.88914289 15.24722657]\nStandard deviations: [1.02742606 0.60258656 1.91702651]\nWeights: [0.23449983 0.10264522 0.66285495]\n\n\n\ndef mixture_pdf(x):  \n  return sum([weight * ss.norm(**param).pdf(x) for weight, param in zip(weights, params)])\n\nmesh = np.linspace(8, 22, num=200)\n\nsns.histplot(data=data, color=yellow, alpha=0.5, ec=grey, zorder=2, stat=\"density\", label=\"data\")\nplt.plot(mesh, mixture_pdf(mesh), color=blue, label=\"GMM PDF\")\nplt.xlabel(\"x = number of cookies\")\nplt.ylabel(\"density\")\nplt.title(\"data + GMM PDF\")\nplt.legend()\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/shiny-clt/index.html",
    "href": "posts/shiny-clt/index.html",
    "title": "‚ÄúShiny‚Äù Central Limit Theorem",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Curabitur nec eros eget nisl posuere fermentum. Phasellus vitae augue nec justo commodo gravida."
  },
  {
    "objectID": "posts/shiny-clt/index.html#header-1",
    "href": "posts/shiny-clt/index.html#header-1",
    "title": "‚ÄúShiny‚Äù Central Limit Theorem",
    "section": "Header 1",
    "text": "Header 1\nLoad R libraries:\n\nlibrary(\"ggplot2\")\nlibrary(\"latex2exp\")\nlibrary(\"reticulate\") \ncondaenv.name &lt;- \"default-env\"\nuse_condaenv(condaenv.name, required = TRUE)\n\nLoad Python libraries:\n\nimport scipy.stats as ss\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nConstruct the PDF for the mixture of Gaussians:\n\nweights &lt;- c(0.2, 0.3, 0.1, 0.4)\nmeans &lt;- c(0, 3, 5, 10)\nsds &lt;- c(1, 0.75, 0.5, 2)\n\nmixture.pdf &lt;- function(x) {\n  rowSums(\n    sapply(\n      X = seq_along(weights),\n      FUN = function(i) weights[i] * dnorm(x, mean = means[i], sd = sds[i])\n    )\n  )\n}\n\nPlot the PDF of the mixture of Gaussians:\n\n\nCode\nggplot(data.frame(x = c(-4, 14)), aes(x)) +\n  stat_function(fun = mixture.pdf, color = yellow, linewidth = 1, n = 250) +\n  labs(y = \"density\", title = \"mixture of gaussians\")\n\n\n\n\n\n\n\n\n\nDefine an R function for plotting sampling distributions of the mean:\n\nplot.sampling.dist &lt;- function(df.sample, n.sample, mu, sigma, bins = 50, alpha = 0.5) {\n  \n  ggplot(df.sample, aes(x = xbar)) +\n    geom_histogram(\n      aes(y = after_stat(density)),\n      color = grey,\n      bins = bins,\n      alpha = alpha,\n      fill = yellow\n    ) +\n    stat_density(\n      aes(color = \"data\"),\n      geom = \"line\",\n      linewidth = 1\n    ) +\n    stat_function(\n      aes(color = \"normal\"),\n      fun = function(x) dnorm(x, mean = mu, sd = sigma),\n      linewidth = 1   \n    ) + \n    scale_color_manual(\n      name = NULL,\n      values = c(\"data\" = yellow, \"normal\" = blue)\n    ) +\n    labs(\n      x = TeX(\"$\\\\bar{x}$\"),\n      title = TeX(paste0(\"sampling distribution for $\\\\bar{X}_{\", n.sample, \"}$\"))\n    )\n}\n\nDefine an R function for generating a sample for the sample mean of the mixture of Gaussians:\n\ngenerate.mixture.sample &lt;- function(n.sample, n.replicates, n.components, weights, means, sds) {\n  \n  components &lt;- sample(\n    1:n.components,\n    size = n.replicates * n.sample,\n    replace = TRUE,\n    prob = weights\n  )\n\n  matrix.sample &lt;- matrix(\n    rnorm(n.replicates * n.sample, mean = means[components], sd = sds[components]),\n    nrow = n.replicates,\n    ncol = n.sample\n  )\n\n  df.sample &lt;- data.frame(xbar = rowMeans(matrix.sample))\n  \n  return(df.sample)\n}\n\nDefine an R function for computing the mean and standard deviation of the mixture of Gaussians:\n\ngenerate.mixture.stats &lt;- function(n.sample, weights, means, sds) {\n\n  second.moments &lt;- means ** 2 + sds ** 2\n  mu &lt;- as.numeric(weights %*% means)\n  sigma &lt;- sqrt(as.numeric(weights %*% second.moments - (weights %*% means) ** 2) / n.sample)\n  \n  return(c(mu = mu, sigma = sigma))\n}\n\nPlot the sample mean \\(\\overline{X}_3\\) of the mixture of Gaussians:\n\n\nCode\nn.sample &lt;- 3\nn.replicates &lt;- 1000\nn.components &lt;- 4\n\ndf.sample &lt;- generate.mixture.sample(n.sample, n.replicates, n.components, weights, means, sds)\nstats &lt;- generate.mixture.stats(n.sample, weights, means, sds)\n\nplot.sampling.dist(df.sample, n.sample, stats[\"mu\"], stats[\"sigma\"])\n\n\n\n\n\n\n\n\n\nPlot the sample mean \\(\\overline{X}_{10}\\) of the mixture of Gaussians:\n\n\nCode\nn.sample &lt;- 10\n\ndf.sample &lt;- generate.mixture.sample(n.sample, n.replicates, n.components, weights, means, sds)\nstats &lt;- generate.mixture.stats(n.sample, weights, means, sds)\n\nplot.sampling.dist(df.sample, n.sample, stats[\"mu\"], stats[\"sigma\"])\n\n\n\n\n\n\n\n\n\nPlot the sample mean \\(\\overline{X}_{100}\\) of the mixture of Gaussians:\n\n\nCode\nn.sample &lt;- 100\n\ndf.sample &lt;- generate.mixture.sample(n.sample, n.replicates, n.components, weights, means, sds)\nstats &lt;- generate.mixture.stats(n.sample, weights, means, sds)\n\nplot.sampling.dist(df.sample, n.sample, stats[\"mu\"], stats[\"sigma\"])\n\n\n\n\n\n\n\n\n\nPlot the PDF of a log-normal distribution in Python:\n\n\nCode\nmeanlog = 1\nsdlog = 0.75\nX = ss.lognorm(s=sdlog, scale=np.exp(meanlog))\n\nlognorm_mean = X.mean()\n\nx_grid = np.linspace(0, 13, num=250)\n\n_, ax = plt.subplots()\nax.plot(x_grid, X.pdf(x_grid), color=yellow)\nax.set_title('log-normal')\nax.set_xlabel('x')\nax.set_ylabel('density')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "john myers, ph.d.",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Curabitur nec eros eget nisl posuere fermentum. Phasellus vitae augue nec justo commodo gravida. Vivamus euismod, nisi a tristique dictum, sapien libero tempor nulla, sit amet dignissim justo elit sit amet lectus. Sed euismod risus a felis facilisis, in tincidunt purus luctus.\n\n\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Curabitur nec eros eget nisl posuere fermentum. Phasellus vitae augue nec justo commodo gravida. Vivamus euismod, nisi a tristique dictum, sapien libero tempor nulla, sit amet dignissim justo elit sit amet lectus. Sed euismod risus a felis facilisis, in tincidunt purus luctus. Blah! Blah! Blah! Blah! Blah! Blah! Blah! Blah!\n\n\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Curabitur nec eros eget nisl posuere fermentum. Phasellus vitae augue nec justo commodo gravida. Vivamus euismod, nisi a tristique dictum, sapien libero tempor nulla, sit amet dignissim justo elit sit amet lectus. Sed euismod risus a felis facilisis, in tincidunt purus luctus."
  },
  {
    "objectID": "courses/25-fa-calculus-ii.html",
    "href": "courses/25-fa-calculus-ii.html",
    "title": "mat220 calculus II, fall 2025",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Curabitur nec eros eget nisl posuere fermentum. Phasellus vitae augue nec justo commodo gravida. Vivamus euismod, nisi a tristique dictum, sapien libero tempor nulla, sit amet dignissim justo elit sit amet lectus. Sed euismod risus a felis facilisis, in tincidunt purus luctus."
  }
]